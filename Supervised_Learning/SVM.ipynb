{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‰ğŸš€  \n",
    "\n",
    "---\n",
    "\n",
    "# ğŸ¯ **Understanding Support Vector Machines (SVMs) in Detail!**  \n",
    "\n",
    "## **ğŸ“Œ Step 1: Importing Required Libraries**  \n",
    "The **first step** in any **machine learning** project is to **import the required libraries**. These libraries provide us with the necessary functions for **data processing, visualization, model training, and evaluation**.  \n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "```\n",
    "\n",
    "### ğŸ” **Breaking Down the Imports:**\n",
    "1ï¸âƒ£ `import numpy as np` â¡ **NumPy** helps with numerical computations, arrays, and mathematical operations. ğŸ§®ğŸ“Š  \n",
    "\n",
    "2ï¸âƒ£ `import matplotlib.pyplot as plt` â¡ **Matplotlib** is a visualization library that helps create graphs, scatter plots, and decision boundaries. ğŸ“ˆğŸ¨  \n",
    "\n",
    "3ï¸âƒ£ `from sklearn.svm import SVC, SVR`  \n",
    "   - **SVC (Support Vector Classifier)** â¡ Used for classification tasks (predicting categories like spam vs non-spam). ğŸ“©âœ…  \n",
    "   - **SVR (Support Vector Regression)** â¡ Used for regression tasks (predicting continuous values like temperature). ğŸŒ¡ğŸ“‰  \n",
    "\n",
    "4ï¸âƒ£ `from sklearn.datasets import make_classification, make_regression`  \n",
    "   - `make_classification()` â¡ Generates synthetic **classification** data for models. ğŸ­ğŸ“Š  \n",
    "   - `make_regression()` â¡ Generates synthetic **regression** data for predicting numerical values.  \n",
    "\n",
    "5ï¸âƒ£ `from sklearn.model_selection import train_test_split`  \n",
    "   - Splits the dataset into **training** and **testing** sets. Training is for model learning, and testing is for evaluation. ğŸ“ğŸ”¬  \n",
    "\n",
    "6ï¸âƒ£ `from sklearn.preprocessing import StandardScaler`  \n",
    "   - Standardizes data so that all features have a **mean of 0** and **standard deviation of 1**. This improves SVM performance. ğŸ“âš–  \n",
    "\n",
    "7ï¸âƒ£ `from sklearn.metrics import accuracy_score, mean_squared_error`  \n",
    "   - **`accuracy_score()`** â¡ Measures how **many predictions** were correct for classification. ğŸ¯âœ…  \n",
    "   - **`mean_squared_error()`** â¡ Measures how **far the predictions are** from actual values in regression. ğŸ“ğŸ“‰  \n",
    "\n",
    "8ï¸âƒ£ `from sklearn.pipeline import make_pipeline`  \n",
    "   - A **pipeline** helps in chaining multiple steps together, like **scaling data** before passing it to the SVM model. ğŸ”—ğŸ›   \n",
    "\n",
    "9ï¸âƒ£ `from sklearn.svm import LinearSVC`  \n",
    "   - **LinearSVC** is an optimized version of **SVC** when using a **linear kernel**. It is **faster and efficient** for large datasets. ğŸš€âš¡  \n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ“Œ Step 2: Support Vector Classifier (SVC)**\n",
    "Now, let's **generate a classification dataset** and train an **SVM model** to **classify data into two categories**. ğŸ·ğŸ­  \n",
    "\n",
    "```python\n",
    "print(\"\\n--- Support Vector Classifier (SVC) ---\\n\")\n",
    "X, y = make_classification(n_samples=500, n_features=2, n_classes=2, random_state=42)\n",
    "```\n",
    "- **`make_classification(n_samples=500, n_features=2, n_classes=2, random_state=42)`**  \n",
    "  - Generates **500 samples**, with **2 features per sample**.  \n",
    "  - The data is **divided into 2 classes** (Binary Classification).  \n",
    "  - `random_state=42` ensures the **same dataset** is created every time we run the code. ğŸ²ğŸ”„  \n",
    "\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "- **Splitting Data into Training & Testing Sets**  \n",
    "  - `X_train`, `y_train` â¡ **Used to train the model** ğŸ‹ï¸â€â™‚ï¸ğŸ“š  \n",
    "  - `X_test`, `y_test` â¡ **Used to evaluate the model** ğŸ§ªğŸ”¬  \n",
    "  - `test_size=0.2` â¡ **20% of data is reserved for testing.**  \n",
    "\n",
    "```python\n",
    "svc = make_pipeline(StandardScaler(), SVC(kernel='linear', C=1.0))\n",
    "```\n",
    "- **Creating the SVM Model** ğŸ¯  \n",
    "  - **`StandardScaler()`** â¡ **Normalizes the data** before passing it to the model. ğŸ“ğŸ“Š  \n",
    "  - **`SVC(kernel='linear', C=1.0)`** â¡ Uses a **linear kernel** for classification.  \n",
    "  - **C=1.0** â¡ Controls **how much misclassified points** are penalized. Higher `C` = fewer misclassifications. âœ…  \n",
    "\n",
    "```python\n",
    "svc.fit(X_train, y_train)\n",
    "```\n",
    "- **Training the SVM classifier** using the **training data**. ğŸ‹ï¸â€â™‚ï¸ğŸ“  \n",
    "\n",
    "```python\n",
    "y_pred = svc.predict(X_test)\n",
    "```\n",
    "- **Making Predictions** on unseen **test data**. ğŸ¤–ğŸ“Š  \n",
    "\n",
    "```python\n",
    "print(\"SVC Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "```\n",
    "- **Evaluating Model Performance**  \n",
    "  - Compares predicted labels (`y_pred`) with actual labels (`y_test`). âœ…  \n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ“Œ Step 3: Trying Different SVM Kernels**\n",
    "SVM can use **different kernels** to handle **complex patterns**. Let's test them all! ğŸ­ğŸ”¬  \n",
    "\n",
    "```python\n",
    "print(\"\\n--- SVM Kernels Implementation ---\\n\")\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "```\n",
    "- We define a list of **kernel functions** to try. ğŸ”ğŸ“š  \n",
    "\n",
    "```python\n",
    "for kernel in kernels:\n",
    "    model = make_pipeline(StandardScaler(), SVC(kernel=kernel, C=1.0, degree=3 if kernel == 'poly' else None))\n",
    "```\n",
    "- **Iterating Through Different Kernels** ğŸ”„  \n",
    "  - `linear` â¡ Best for **simple, linearly separable data**. ğŸ“âœ…  \n",
    "  - `poly` â¡ Uses **polynomial transformation** (good for curved boundaries). ğŸ”„âœ¨  \n",
    "  - `rbf` â¡ **Radial Basis Function Kernel**, great for **complex non-linear data**. ğŸ”¥ğŸŒ€  \n",
    "  - `sigmoid` â¡ Similar to **neural networks**, maps data to a **higher dimension**. ğŸ¤–ğŸ§   \n",
    "\n",
    "```python\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(f\"{kernel} Kernel Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "```\n",
    "- **Train & Test Each Kernel** ğŸ‹ï¸â€â™‚ï¸ğŸ”¬  \n",
    "\n",
    "---\n",
    "\n",
    "## **ğŸ“Œ Step 4: Visualizing Decision Boundaries**\n",
    "SVM decision boundaries help understand **how well the model is classifying the data**. ğŸ“ŠğŸ¨  \n",
    "\n",
    "```python\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axes = axes.ravel()\n",
    "```\n",
    "- **Creating a 2x2 grid of subplots** for visualization. ğŸ“ŠğŸ”  \n",
    "\n",
    "```python\n",
    "for i, kernel in enumerate(kernels):\n",
    "    model = make_pipeline(StandardScaler(), SVC(kernel=kernel, C=1.0))\n",
    "    model.fit(X_train, y_train)\n",
    "```\n",
    "- **Training a Model for Each Kernel** ğŸš€  \n",
    "\n",
    "```python\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "```\n",
    "- **Generating Grid Points for Decision Boundary** ğŸ“ğŸ“Š  \n",
    "\n",
    "```python\n",
    "Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "```\n",
    "- **Predicting Labels for Grid Points** ğŸ¯âœ…  \n",
    "\n",
    "```python\n",
    "axes[i].contourf(xx, yy, Z, alpha=0.3)\n",
    "axes[i].scatter(X[:, 0], X[:, 1], c=y, edgecolor='k')\n",
    "axes[i].set_title(f\"SVM with {kernel} kernel\")\n",
    "```\n",
    "- **Plotting Decision Boundaries for Each Kernel** ğŸ¨ğŸ“Š  \n",
    "\n",
    "---\n",
    "\n",
    " ğŸš€ğŸ”¥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.datasets import make_classification, make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# --- Step 2: Support Vector Classifier (SVC) ---\n",
    "print(\"\\n--- Support Vector Classifier (SVC) ---\\n\")\n",
    "X, y = make_classification(n_samples=500, n_features=2, n_classes=2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "svc = make_pipeline(StandardScaler(), SVC(kernel='linear', C=1.0))\n",
    "svc.fit(X_train, y_train)\n",
    "y_pred = svc.predict(X_test)\n",
    "print(\"SVC Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# --- Step 3: Trying Different SVM Kernels ---\n",
    "print(\"\\n--- SVM Kernels Implementation ---\\n\")\n",
    "kernels = ['linear', 'poly', 'rbf', 'sigmoid']\n",
    "\n",
    "for kernel in kernels:\n",
    "    model = make_pipeline(StandardScaler(), SVC(kernel=kernel, C=1.0, degree=3 if kernel == 'poly' else None))\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"{kernel} Kernel Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# --- Step 4: Visualizing Decision Boundaries ---\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, kernel in enumerate(kernels):\n",
    "    model = make_pipeline(StandardScaler(), SVC(kernel=kernel, C=1.0))\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "    \n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    axes[i].contourf(xx, yy, Z, alpha=0.3)\n",
    "    axes[i].scatter(X[:, 0], X[:, 1], c=y, edgecolor='k')\n",
    "    axes[i].set_title(f\"SVM with {kernel} kernel\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
