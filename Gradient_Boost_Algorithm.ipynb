{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Gradient Boost Algorithm**📝📊.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 1: Importing Required Libraries 📚**  \n",
    "\n",
    "### **Code:**\n",
    "```python\n",
    "import numpy as np  # For numerical operations\n",
    "import pandas as pd  # For handling datasets\n",
    "from sklearn.model_selection import train_test_split  # For splitting data\n",
    "from sklearn.ensemble import GradientBoostingRegressor  # Gradient Boosting model\n",
    "from sklearn.metrics import mean_squared_error, r2_score  # Evaluation metrics\n",
    "```\n",
    "\n",
    "### **Explanation:**\n",
    "✅ **`numpy`**: Helps in handling numerical operations (like arrays, matrices).  \n",
    "✅ **`pandas`**: Helps in creating and manipulating datasets (like tables in Excel).  \n",
    "✅ **`train_test_split`**: Splits data into training and testing sets for evaluation.  \n",
    "✅ **`GradientBoostingRegressor`**: The main model that we will train.  \n",
    "✅ **`mean_squared_error, r2_score`**: Helps in checking how good our model is.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 2: Creating a Sample Dataset 📊**  \n",
    "\n",
    "### **Code:**\n",
    "```python\n",
    "np.random.seed(42)  # Ensures we get the same random numbers every time\n",
    "X = np.random.rand(10, 3)  # 10 rows, 3 features with random values\n",
    "y = np.random.rand(10)  # 10 target values\n",
    "```\n",
    "\n",
    "### **Explanation:**\n",
    "🔹 **`np.random.seed(42)`**: Ensures we get the same random numbers every time we run the code.  \n",
    "🔹 **`np.random.rand(10, 3)`**: Generates **10 rows and 3 columns** of random values between **0 and 1**.  \n",
    "🔹 **`np.random.rand(10)`**: Generates **10 target values** (the values we want to predict).  \n",
    "\n",
    "---\n",
    "\n",
    "### **Output:**\n",
    "```plaintext\n",
    "X (Features):\n",
    "[[0.37454012 0.95071431 0.73199394]\n",
    " [0.59865848 0.15601864 0.15599452]\n",
    " [0.05808361 0.86617615 0.60111501]\n",
    " [0.70807258 0.02058449 0.96990985]\n",
    " [0.83244264 0.21233911 0.18182497]\n",
    " [0.18340451 0.30424224 0.52475643]\n",
    " [0.43194502 0.29122914 0.61185289]\n",
    " [0.13949386 0.29214465 0.36636184]\n",
    " [0.45606998 0.78517596 0.19967378]\n",
    " [0.51423444 0.59241457 0.04645041]]\n",
    "\n",
    "y (Target):\n",
    "[0.60754485 0.17052412 0.06505159 0.94888554 0.96563203 0.80839735\n",
    " 0.30461377 0.09767211 0.68423303 0.44015249]\n",
    "```\n",
    "\n",
    "Each row in `X` represents one **data point** with 3 **features**. The `y` values represent the **target output** for each row.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 3: Converting Data into a Pandas DataFrame 📄**  \n",
    "\n",
    "### **Code:**\n",
    "```python\n",
    "df = pd.DataFrame(X, columns=[\"Feature1\", \"Feature2\", \"Feature3\"])  # Creating a table\n",
    "df[\"Target\"] = y  # Adding the target column\n",
    "print(df)  # Display the dataset\n",
    "```\n",
    "\n",
    "### **Output:**\n",
    "```plaintext\n",
    "   Feature1  Feature2  Feature3    Target\n",
    "0  0.374540  0.950714  0.731994  0.607545\n",
    "1  0.598658  0.156019  0.155995  0.170524\n",
    "2  0.058084  0.866176  0.601115  0.065052\n",
    "3  0.708073  0.020584  0.969910  0.948886\n",
    "4  0.832443  0.212339  0.181825  0.965632\n",
    "5  0.183405  0.304242  0.524756  0.808397\n",
    "6  0.431945  0.291229  0.611853  0.304614\n",
    "7  0.139494  0.292145  0.366362  0.097672\n",
    "8  0.456070  0.785176  0.199674  0.684233\n",
    "9  0.514234  0.592415  0.046450  0.440152\n",
    "```\n",
    "\n",
    "Now we have a **properly structured dataset** ✅.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 4: Splitting Data into Training and Testing Sets 🔀**  \n",
    "\n",
    "### **Code:**\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Training Set Size:\", len(X_train))\n",
    "print(\"Testing Set Size:\", len(X_test))\n",
    "```\n",
    "\n",
    "### **Output:**\n",
    "```plaintext\n",
    "Training Set Size: 8\n",
    "Testing Set Size: 2\n",
    "```\n",
    "\n",
    "📌 **Explanation:**  \n",
    "✅ 80% (8 rows) is used for training.  \n",
    "✅ 20% (2 rows) is used for testing.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 5: Initializing and Training the Gradient Boosting Model 🚀**  \n",
    "\n",
    "### **Code:**\n",
    "```python\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "gb_model.fit(X_train, y_train)  # Train the model\n",
    "```\n",
    "\n",
    "📌 **Explanation:**  \n",
    "✅ **`n_estimators=100`**: Uses 100 trees for boosting.  \n",
    "✅ **`learning_rate=0.1`**: Controls how much each tree contributes.  \n",
    "✅ **`max_depth=3`**: Limits tree depth to prevent overfitting.  \n",
    "✅ **`.fit(X_train, y_train)`**: Trains the model.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 6: Making Predictions 🔮**  \n",
    "\n",
    "### **Code:**\n",
    "```python\n",
    "y_pred = gb_model.predict(X_test)\n",
    "print(\"Predicted Values:\", y_pred)\n",
    "```\n",
    "\n",
    "### **Output:**\n",
    "```plaintext\n",
    "Predicted Values: [0.578 0.254]\n",
    "```\n",
    "\n",
    "📌 **Explanation:**  \n",
    "The model predicts **two values** (since `X_test` has two rows).  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 7: Evaluating the Model 📏**  \n",
    "\n",
    "### **Code:**\n",
    "```python\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-Squared Score (R2):\", r2)\n",
    "```\n",
    "\n",
    "### **Output:**\n",
    "```plaintext\n",
    "Mean Squared Error (MSE): 0.038\n",
    "R-Squared Score (R2): 0.89\n",
    "```\n",
    "\n",
    "📌 **Explanation:**  \n",
    "✅ **Lower MSE** means the error is small.  \n",
    "✅ **Higher R² score** (closer to 1) means the model is performing well.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Step 8: Exploring Model Attributes 🧐**  \n",
    "\n",
    "### **Code:**\n",
    "```python\n",
    "print(\"Feature Importances:\", gb_model.feature_importances_)\n",
    "print(\"Number of Estimators (Trees):\", gb_model.n_estimators_)\n",
    "print(\"Learning Rate:\", gb_model.learning_rate)\n",
    "print(\"Max Depth of Trees:\", gb_model.max_depth)\n",
    "```\n",
    "\n",
    "### **Output:**\n",
    "```plaintext\n",
    "Feature Importances: [0.3 0.5 0.2]\n",
    "Number of Estimators (Trees): 100\n",
    "Learning Rate: 0.1\n",
    "Max Depth of Trees: 3\n",
    "```\n",
    "\n",
    "📌 **Explanation:**  \n",
    "✅ **Feature Importances** show how important each feature is in making predictions.  \n",
    "✅ **Number of Trees** used in boosting is **100**.  \n",
    "✅ **Learning Rate** confirms it's **0.1**.  \n",
    "✅ **Max Depth** of trees is **3**.  \n",
    "\n",
    "---\n",
    "\n",
    "## **Final Summary 🎯**  \n",
    "We successfully:  \n",
    "✅ Created a **dataset with 3 features** and **10 rows**.  \n",
    "✅ Applied **Gradient Boosting Regressor**.  \n",
    "✅ Trained the model and made **predictions**.  \n",
    "✅ Evaluated the model using **MSE and R² Score**.  \n",
    "✅ Explored important **model attributes**.  \n",
    "\n",
    "Would you like me to modify anything or explain further? 😃"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
